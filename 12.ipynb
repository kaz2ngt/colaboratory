{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaz2ngt/colaboratory/blob/master/12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OhZvfh5f7ZO",
        "colab_type": "text"
      },
      "source": [
        "# 事前準備: ドライブのマウントとデータの取得"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DGhBkrkf-nx",
        "colab_type": "code",
        "outputId": "762e2875-d974-41bf-c8ba-5e6e9a513609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Google ドライブをマウントするには、このセルを実行してください。\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PpStTZof_V3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 下記でdriveからコピーして解凍\n",
        "!cp drive/My\\ Drive/Colab\\ Notebooks/12data.zip ./\n",
        "!unzip 12data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKgBwI6G8aRO",
        "colab_type": "text"
      },
      "source": [
        "# リストPART2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZrZwgeF8cih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import math\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.python import keras\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.models import Model, Sequential\n",
        "from tensorflow.python.keras.layers import Conv2D, Dense, Input, MaxPooling2D, UpSampling2D, Lambda\n",
        "from tensorflow.python.keras.preprocessing.image import load_img, img_to_array, array_to_img, ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgk8jxkkXDfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 足りないimport追加\n",
        "from tensorflow.python.keras.layers import Flatten, Reshape\n",
        "from tensorflow.python.keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYAKWzb7NLyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 足りないmethod追加\n",
        "def save_imgs(path, imgs, rows, cols):\n",
        "    \"\"\"画像をタイル状にならべて保存する\n",
        "\n",
        "    Arguments:\n",
        "        path (str): 保存先のファイルパス\n",
        "        imgs (np.array): 保存する画像のリスト\n",
        "        rows (int): タイルの縦のサイズ\n",
        "        cols (int): タイルの横のサイズ\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    base_width = imgs.shape[1]\n",
        "    base_height = imgs.shape[2]\n",
        "    channels = imgs.shape[3]\n",
        "    output_shape = (\n",
        "        base_height * rows,\n",
        "        base_width * cols,\n",
        "        channels\n",
        "    )\n",
        "    buffer = np.zeros(output_shape)\n",
        "    for row in range(rows):\n",
        "        for col in range(cols):\n",
        "            img = imgs[row * cols + col]\n",
        "            buffer[\n",
        "            row * base_height:(row + 1) * base_height,\n",
        "            col * base_width:(col + 1) * base_width\n",
        "            ] = img\n",
        "    array_to_img(buffer).save(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkS8po7YArEp",
        "colab_type": "text"
      },
      "source": [
        "# 12_1: 画像データの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5gK8aJTNb4J",
        "colab_type": "code",
        "outputId": "a47e6944-c07d-45a4-b93c-b34e3739b9eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "DATA_DIR = 'data/chap12/'\n",
        "BATCH_SIZE = 16\n",
        "IMG_SHAPE = (64, 64, 3)\n",
        "\n",
        "data_gen = ImageDataGenerator(rescale=1/255.)\n",
        "train_data_generator = data_gen.flow_from_directory(\n",
        "    directory=DATA_DIR,\n",
        "    classes=['faces'],\n",
        "    class_mode=None,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    target_size=IMG_SHAPE[:2]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 19370 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkSlBBB8PAND",
        "colab_type": "text"
      },
      "source": [
        "# 12_2: Encoderの定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IciFPcPFPHFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_encoder(input_shape, z_size, n_filters, n_layers):\n",
        "  \"\"\"Encoderを構築する\n",
        "\n",
        "  Arguments:\n",
        "    input_shape (int): 画像のshape\n",
        "    z_size (int): 特徴空間の次元数\n",
        "    n_filters (int): フィルタ数\n",
        "\n",
        "  Returns:\n",
        "   model (Model): Encoderモデル\n",
        "  \"\"\"\n",
        "  model = Sequential()\n",
        "  model.add(\n",
        "      Conv2D(\n",
        "          n_filters,\n",
        "          3,\n",
        "          activation='elu',\n",
        "          input_shape=input_shape,\n",
        "          padding='same'\n",
        "      )\n",
        "  )\n",
        "  model.add(Conv2D(n_filters, 3, padding='same'))\n",
        "  for i in range(2, n_layers + 1):\n",
        "    model.add(\n",
        "        Conv2D(\n",
        "            i*n_filters,\n",
        "            3,\n",
        "            activation='elu',\n",
        "            padding='same'\n",
        "        )\n",
        "    )\n",
        "    model.add(\n",
        "        Conv2D(\n",
        "            i*n_filters,\n",
        "            3,\n",
        "            activation='elu',\n",
        "            strides=2,\n",
        "            padding='same'\n",
        "        )\n",
        "    )\n",
        "  model.add(Conv2D(n_layers*n_filters, 3, padding='same'))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(z_size))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XieTuBn3RBCO",
        "colab_type": "text"
      },
      "source": [
        "# 12_3: Generator/Decoderの定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY9nAR60RHi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_decoder(output_shape, z_size, n_filters, n_layers):\n",
        "  \"\"\"Decoderを構築する\n",
        "\n",
        "  Arguments:\n",
        "    output_shape (np.array): 画像のshape\n",
        "    z_site (int): 特徴空間の次元数\n",
        "    n_filters (int): フィルタ数\n",
        "    n_layers (int): レイヤー数\n",
        "\n",
        "  Returns:\n",
        "    model (Model):  Decoderモデル\n",
        "  \"\"\"\n",
        "  # UpSampling2Dで何倍に拡大されるか\n",
        "  scale = 2**(n_layers - 1)\n",
        "  # 最初の畳み込み層の入力サイズをscaleから逆算\n",
        "  fc_shape = (\n",
        "      output_shape[0]//scale,\n",
        "      output_shape[1]//scale,\n",
        "      n_filters\n",
        " )\n",
        "  # 全結合層で必要なサイズを逆算\n",
        "  fc_size = fc_shape[0]*fc_shape[1]*fc_shape[2]\n",
        "\n",
        "  model = Sequential()\n",
        "  # 全結合層\n",
        "  model.add(Dense(fc_size, input_shape=(z_size,)))\n",
        "  model.add(Reshape(fc_shape))\n",
        "\n",
        "  # 畳み込み層の繰り返し\n",
        "  for i in range(n_layers - 1):\n",
        "    model.add(\n",
        "        Conv2D(\n",
        "            n_filters,\n",
        "            3,\n",
        "            activation='elu',\n",
        "            padding='same'\n",
        "        )\n",
        "    )\n",
        "    model.add(\n",
        "        Conv2D(\n",
        "            n_filters,\n",
        "            3,\n",
        "            activation='elu',\n",
        "            padding='same'\n",
        "        )\n",
        "    )\n",
        "    model.add(UpSampling2D())\n",
        "\n",
        "  # 最後の層はUpSampling2Dが不要\n",
        "  model.add(\n",
        "      Conv2D(\n",
        "          n_filters,\n",
        "          3,\n",
        "          activation='elu',\n",
        "          padding='same',\n",
        "      )\n",
        "  )\n",
        "  model.add(\n",
        "      Conv2D(\n",
        "          n_filters,\n",
        "          3,\n",
        "          activation='elu',\n",
        "          padding='same'\n",
        "      )\n",
        "  )\n",
        "  # 出力層で3チャンネルに\n",
        "  model.add(Conv2D(3, 3, padding='same'))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwZNSU4GTW4J",
        "colab_type": "text"
      },
      "source": [
        "# 12_4: Generatorの定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ondSX_g2TZky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator(img_shape, z_size, n_filters, n_layers):\n",
        "  decoder = build_decoder(\n",
        "      img_shape, z_size, n_filters, n_layers\n",
        "  )\n",
        "  return decoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SS_C1RETnTY",
        "colab_type": "text"
      },
      "source": [
        "# 12_5: Discriminatorの定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsbrzAg3Tq6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator(img_shape, z_size, n_filters, n_layers):\n",
        "  encoder = build_encoder(\n",
        "      img_shape, z_size, n_filters, n_layers\n",
        "  )\n",
        "  decoder = build_decoder(\n",
        "      img_shape, z_size, n_filters, n_layers\n",
        "  )\n",
        "  return Sequential((encoder, decoder))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd1PacHDVj3k",
        "colab_type": "text"
      },
      "source": [
        "# 12_6: Discriminatorの学習用のネットワーク"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX9vVymNVqqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator_trainer(discriminator):\n",
        "  img_shape = discriminator.input_shape[1:]\n",
        "  real_inputs = Input(img_shape)\n",
        "  fake_inputs = Input(img_shape)\n",
        "  real_outputs = discriminator(real_inputs)\n",
        "  fake_outputs = discriminator(fake_inputs)\n",
        "\n",
        "  return Model(\n",
        "      inputs=[real_inputs, fake_inputs],\n",
        "      outputs=[real_outputs, fake_outputs]\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4XtizLJWHUW",
        "colab_type": "text"
      },
      "source": [
        "# 12_7: ネットワークの構築"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCN8k558WLGU",
        "colab_type": "code",
        "outputId": "ed32ab0a-bc39-44b2-aa00-35e20e36086f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_filters = 64 # フィルタ数\n",
        "n_layers = 4# レイヤー数\n",
        "z_size = 32 # 特徴空間の次元数\n",
        "\n",
        "generator = build_generator(\n",
        "    IMG_SHAPE, z_size, n_filters, n_layers\n",
        ")\n",
        "discriminator = build_discriminator(\n",
        "    IMG_SHAPE, z_size, n_filters, n_layers\n",
        ")\n",
        "discriminator_trainer  =  build_discriminator_trainer(\n",
        "    discriminator\n",
        ")\n",
        "\n",
        "generator.summary()\n",
        "# discriminator.layers[1]が Decoder を表す\n",
        "discriminator.layers[1].summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0828 00:03:59.768161 140560677394304 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 4096)              135168    \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 64, 64, 3)         1731      \n",
            "=================================================================\n",
            "Total params: 432,323\n",
            "Trainable params: 432,323\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 4096)              135168    \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2 (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2 (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 64, 64, 3)         1731      \n",
            "=================================================================\n",
            "Total params: 432,323\n",
            "Trainable params: 432,323\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02BrMsUhHnnb",
        "colab_type": "text"
      },
      "source": [
        "# 12_8: 損失関数の定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9_BW1WVHsIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.losses import mean_absolute_error\n",
        "\n",
        "def build_generator_loss(discriminator):\n",
        "  # discriminator を使って損失関数を定義\n",
        "  def loss(y_true, y_pred):\n",
        "    # y_true はダミー\n",
        "    reconst = discriminator(y_pred)\n",
        "    return mean_absolute_error(\n",
        "        reconst,\n",
        "        y_pred\n",
        "    )\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P2bZ88JIFly",
        "colab_type": "text"
      },
      "source": [
        "# 12_9: generatorのコンパイル"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XNkgufMIIiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 初期の学習率(Generator)\n",
        "g_lr = 0.0001\n",
        "\n",
        "generator_loss = build_generator_loss(discriminator)\n",
        "generator.compile(\n",
        "    loss=generator_loss,\n",
        "    optimizer=Adam(g_lr)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv6y3x1uIzHd",
        "colab_type": "text"
      },
      "source": [
        "# 12_10: discriminatorのコンパイル"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JDOTOFEJIU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 初期の学習率(Discriminator)\n",
        "d_lr = 0.0001\n",
        "\n",
        "# k_varは数値(普通の変数)\n",
        "k_var = 0.0\n",
        "# k はKeras(TensorFlow)のVariable\n",
        "k = K.variable(k_var)\n",
        "discriminator_trainer.compile(\n",
        "    loss=[\n",
        "        mean_absolute_error,\n",
        "        mean_absolute_error\n",
        "    ],\n",
        "    loss_weights=[1., -k],\n",
        "    optimizer=Adam(d_lr)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5hKMcEqJyza",
        "colab_type": "text"
      },
      "source": [
        "# 12_11: 収束判定用の関数定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3MBhQeGJ3hV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def measure(real_loss,  fake_loss,  gamma):\n",
        "  return real_loss + np.abs(gamma*real_loss - fake_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slBdUDaMKCZq",
        "colab_type": "text"
      },
      "source": [
        "# 12_12: 学習のコード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHdxq_W1KE-S",
        "colab_type": "code",
        "outputId": "99c9bf29-6a6d-4405-ec6d-6dc605d571e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# k の更新に利用するパラメータ\n",
        "GAMMA = 0.5\n",
        "LR_K = 0.001\n",
        "\n",
        "\n",
        "# 繰り返し数。100000~1000000程度を指定\n",
        "TOTAL_STEPS = 100000\n",
        "\n",
        "# モデルや確認用の生成画像を保存するディレクトリ\n",
        "MODEL_SAVE_DIR = 'began_s/models'\n",
        "IMG_SAVE_DIR = 'began_s/imgs'\n",
        "# 確認用に 5x5 個の画像を生成する\n",
        "IMG_SAMPLE_SHAPE = (5, 5)\n",
        "N_IMG_SAMPLES = np.prod(IMG_SAMPLE_SHAPE)\n",
        "\n",
        "# 保存先がなければ作成\n",
        "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
        "os.makedirs(IMG_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# サンプル画像用のランダムシード\n",
        "sample_seeds = np.random.uniform(\n",
        "    -1, 1, (N_IMG_SAMPLES, z_size)\n",
        ")\n",
        "\n",
        "history = []\n",
        "logs = []\n",
        "\n",
        "for step, batch in enumerate(train_data_generator):\n",
        "  # サンプル数が BATCH_SIZE に満たない場合はスキップ\n",
        "  # 全体の画像枚数が BATCH_SIZE の倍数でない場合に発生\n",
        "  if len(batch) < BATCH_SIZE:\n",
        "    continue\n",
        "\n",
        "  # 学習終了\n",
        "  if step > TOTAL_STEPS:\n",
        "    break\n",
        "\n",
        "  # ランダムな値を生成\n",
        "  z_g =  np.random.uniform(\n",
        "      -1, 1, (BATCH_SIZE, z_size)\n",
        "  )\n",
        "  z_d =  np.random.uniform(\n",
        "      -1, 1, (BATCH_SIZE, z_size)\n",
        "  )\n",
        "\n",
        "  # 生成画像 (discriminatorの学習に利用)\n",
        "  g_pred = generator.predict(z_d)\n",
        "\n",
        "  # generator を1ステップ分学習させる\n",
        "  generator.train_on_batch(z_g, batch)\n",
        "  # discriminator を1ステップ分学習させる\n",
        "  _, real_loss, fake_loss = discriminator_trainer.train_on_batch(\n",
        "      [batch, g_pred],\n",
        "      [batch, g_pred]\n",
        "  )\n",
        "  # k を更新\n",
        "  k_var += LR_K*(GAMMA*real_loss - fake_loss)\n",
        "  K.set_value(k, k_var)\n",
        "\n",
        "  # g_measure を計算するためにlossを保存\n",
        "  history.append({\n",
        "      'real_loss': real_loss,\n",
        "      'fake_loss': fake_loss\n",
        "  })\n",
        "\n",
        "  # 1000回に1度ログを表示\n",
        "  if step%1000 == 0:\n",
        "    # 過去1000回分の measure を平均\n",
        "    measurement = np.mean([\n",
        "        measure(\n",
        "            loss['real_loss'],\n",
        "            loss['fake_loss'],\n",
        "            GAMMA\n",
        "        )\n",
        "        for loss in history[-1000:]\n",
        "    ])\n",
        "\n",
        "    logs.append({\n",
        "        'k': K.get_value(k),\n",
        "        'measure': measurement,\n",
        "        'real_loss': real_loss,\n",
        "        'fake_loss': fake_loss\n",
        "    })\n",
        "    print(logs[-1])\n",
        "\n",
        "    # 画像を保存\n",
        "    img_path = '{}/generated_{}.png'.format(\n",
        "        IMG_SAVE_DIR,\n",
        "        step\n",
        "    )\n",
        "    save_imgs(\n",
        "        img_path,\n",
        "        generator.predict(sample_seeds),\n",
        "        rows=IMG_SAMPLE_SHAPE[0],\n",
        "        cols=IMG_SAMPLE_SHAPE[1]\n",
        "    )\n",
        "    # 最新のモデルを保存\n",
        "    generator.save('{}/generator_{}.hd5'.format(MODEL_SAVE_DIR, step))\n",
        "    discriminator.save('{}/discriminator_{}.hd5'.format(MODEL_SAVE_DIR, step))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'k': 0.00012911911, 'measure': 0.4794679433107376, 'real_loss': 0.35034883, 'fake_loss': 0.046055302}\n",
            "{'k': 0.035507627, 'measure': 0.145726781161502, 'real_loss': 0.08017315, 'fake_loss': 0.020892639}\n",
            "{'k': 0.049880195, 'measure': 0.1126139170108363, 'real_loss': 0.09410982, 'fake_loss': 0.04782919}\n",
            "{'k': 0.040487435, 'measure': 0.11290999461524188, 'real_loss': 0.0852791, 'fake_loss': 0.057748795}\n",
            "{'k': 0.038235635, 'measure': 0.10297443783655763, 'real_loss': 0.100247905, 'fake_loss': 0.051553573}\n",
            "{'k': 0.0448657, 'measure': 0.09864948162436485, 'real_loss': 0.08979483, 'fake_loss': 0.03644176}\n",
            "{'k': 0.04934461, 'measure': 0.09310711471736431, 'real_loss': 0.09122168, 'fake_loss': 0.040378205}\n",
            "{'k': 0.047206722, 'measure': 0.09947422783821822, 'real_loss': 0.09506133, 'fake_loss': 0.042102866}\n",
            "{'k': 0.025358822, 'measure': 0.12962548524700104, 'real_loss': 0.0931938, 'fake_loss': 0.033776127}\n",
            "{'k': 0.04150757, 'measure': 0.10226894765719771, 'real_loss': 0.07868658, 'fake_loss': 0.02578865}\n",
            "{'k': 0.0512846, 'measure': 0.09475526035018265, 'real_loss': 0.0778068, 'fake_loss': 0.025933202}\n",
            "{'k': 0.066938154, 'measure': 0.09965849849395454, 'real_loss': 0.07499756, 'fake_loss': 0.029044632}\n",
            "{'k': 0.079369225, 'measure': 0.09674573785439133, 'real_loss': 0.089193, 'fake_loss': 0.029870965}\n",
            "{'k': 0.08835433, 'measure': 0.09332503998279572, 'real_loss': 0.09515825, 'fake_loss': 0.032066297}\n",
            "{'k': 0.09534692, 'measure': 0.09193117568455636, 'real_loss': 0.07262229, 'fake_loss': 0.039578743}\n",
            "{'k': 0.10147099, 'measure': 0.09066351816430687, 'real_loss': 0.0853902, 'fake_loss': 0.039271317}\n",
            "{'k': 0.10549032, 'measure': 0.09086915307119489, 'real_loss': 0.085788354, 'fake_loss': 0.032423086}\n",
            "{'k': 0.111705706, 'measure': 0.08994285226985813, 'real_loss': 0.0789846, 'fake_loss': 0.029950367}\n",
            "{'k': 0.11739194, 'measure': 0.08983173137158156, 'real_loss': 0.080967635, 'fake_loss': 0.034289733}\n",
            "{'k': 0.123446904, 'measure': 0.09020140329003334, 'real_loss': 0.0849572, 'fake_loss': 0.0374035}\n",
            "{'k': 0.12768176, 'measure': 0.08849876464903354, 'real_loss': 0.07494284, 'fake_loss': 0.048376776}\n",
            "{'k': 0.13067415, 'measure': 0.08886156934499741, 'real_loss': 0.07383819, 'fake_loss': 0.034298897}\n",
            "{'k': 0.12860289, 'measure': 0.08913190626166761, 'real_loss': 0.08333798, 'fake_loss': 0.063646145}\n",
            "{'k': 0.120231815, 'measure': 0.09282894187793135, 'real_loss': 0.0770966, 'fake_loss': 0.048286833}\n",
            "{'k': 0.11028294, 'measure': 0.09346267889998854, 'real_loss': 0.078481734, 'fake_loss': 0.046375368}\n",
            "{'k': 0.10163775, 'measure': 0.09141302189789713, 'real_loss': 0.08975038, 'fake_loss': 0.03833432}\n",
            "{'k': 0.0946044, 'measure': 0.08990869923122227, 'real_loss': 0.083324924, 'fake_loss': 0.05325208}\n",
            "{'k': 0.089728415, 'measure': 0.08711464415863156, 'real_loss': 0.080015406, 'fake_loss': 0.04372304}\n",
            "{'k': 0.08624678, 'measure': 0.08578619727119803, 'real_loss': 0.07625063, 'fake_loss': 0.033346698}\n",
            "{'k': 0.08355821, 'measure': 0.08560858875885606, 'real_loss': 0.0735623, 'fake_loss': 0.035154067}\n",
            "{'k': 0.08186946, 'measure': 0.08430059394612908, 'real_loss': 0.083635405, 'fake_loss': 0.050106782}\n",
            "{'k': 0.08018183, 'measure': 0.08450650284253061, 'real_loss': 0.07005791, 'fake_loss': 0.04077536}\n",
            "{'k': 0.07869019, 'measure': 0.08417246681824327, 'real_loss': 0.07850383, 'fake_loss': 0.044811096}\n",
            "{'k': 0.0767969, 'measure': 0.08398496289737523, 'real_loss': 0.07381232, 'fake_loss': 0.03304216}\n",
            "{'k': 0.07537056, 'measure': 0.0830744871776551, 'real_loss': 0.0847269, 'fake_loss': 0.04011452}\n",
            "{'k': 0.073624425, 'measure': 0.08310962091386319, 'real_loss': 0.083103605, 'fake_loss': 0.036238424}\n",
            "{'k': 0.07229128, 'measure': 0.08235157241672278, 'real_loss': 0.08325355, 'fake_loss': 0.04512129}\n",
            "{'k': 0.07112783, 'measure': 0.08292545790597797, 'real_loss': 0.0758845, 'fake_loss': 0.03952968}\n",
            "{'k': 0.06885874, 'measure': 0.08270797833055257, 'real_loss': 0.08295372, 'fake_loss': 0.049516212}\n",
            "{'k': 0.06766306, 'measure': 0.08246940813027322, 'real_loss': 0.07774696, 'fake_loss': 0.036417443}\n",
            "{'k': 0.066345535, 'measure': 0.08209598051384091, 'real_loss': 0.07735799, 'fake_loss': 0.042460628}\n",
            "{'k': 0.06450658, 'measure': 0.08251639536954462, 'real_loss': 0.080016606, 'fake_loss': 0.035001427}\n",
            "{'k': 0.06363038, 'measure': 0.0811975407525897, 'real_loss': 0.07275848, 'fake_loss': 0.030109746}\n",
            "{'k': 0.06240032, 'measure': 0.0816224727537483, 'real_loss': 0.077084646, 'fake_loss': 0.03771158}\n",
            "{'k': 0.061952457, 'measure': 0.08111452813632786, 'real_loss': 0.082196526, 'fake_loss': 0.03697247}\n",
            "{'k': 0.060936496, 'measure': 0.08092631814256311, 'real_loss': 0.075540535, 'fake_loss': 0.03721954}\n",
            "{'k': 0.06038147, 'measure': 0.08089099529385567, 'real_loss': 0.07766846, 'fake_loss': 0.039029516}\n",
            "{'k': 0.060008217, 'measure': 0.08004776324145496, 'real_loss': 0.08069667, 'fake_loss': 0.03253358}\n",
            "{'k': 0.058951557, 'measure': 0.08049679486081004, 'real_loss': 0.0799353, 'fake_loss': 0.03788186}\n",
            "{'k': 0.057713863, 'measure': 0.08094967737980187, 'real_loss': 0.07124356, 'fake_loss': 0.040156215}\n",
            "{'k': 0.0574906, 'measure': 0.07927692200802267, 'real_loss': 0.07957858, 'fake_loss': 0.043925107}\n",
            "{'k': 0.056706067, 'measure': 0.07994050668738782, 'real_loss': 0.06817832, 'fake_loss': 0.04226336}\n",
            "{'k': 0.05654111, 'measure': 0.07946957495249808, 'real_loss': 0.077385694, 'fake_loss': 0.034193084}\n",
            "{'k': 0.056576874, 'measure': 0.07903247516788542, 'real_loss': 0.07585238, 'fake_loss': 0.034357503}\n",
            "{'k': 0.056699477, 'measure': 0.07885174173675477, 'real_loss': 0.07984334, 'fake_loss': 0.03676997}\n",
            "{'k': 0.056063324, 'measure': 0.07952403072826564, 'real_loss': 0.07170907, 'fake_loss': 0.03690899}\n",
            "{'k': 0.055291872, 'measure': 0.0785778337623924, 'real_loss': 0.081682794, 'fake_loss': 0.038159993}\n",
            "{'k': 0.054790348, 'measure': 0.07900963266566395, 'real_loss': 0.0758926, 'fake_loss': 0.033318903}\n",
            "{'k': 0.054229345, 'measure': 0.07867306309565902, 'real_loss': 0.075768396, 'fake_loss': 0.03886688}\n",
            "{'k': 0.053752005, 'measure': 0.07838568856194615, 'real_loss': 0.07282322, 'fake_loss': 0.03362795}\n",
            "{'k': 0.0538038, 'measure': 0.07783341893926263, 'real_loss': 0.072332785, 'fake_loss': 0.031765472}\n",
            "{'k': 0.05388054, 'measure': 0.07764136213809252, 'real_loss': 0.062254347, 'fake_loss': 0.035527043}\n",
            "{'k': 0.053661797, 'measure': 0.0778859429154545, 'real_loss': 0.07395029, 'fake_loss': 0.039039366}\n",
            "{'k': 0.05347836, 'measure': 0.07747628485411405, 'real_loss': 0.07010929, 'fake_loss': 0.0382638}\n",
            "{'k': 0.052772585, 'measure': 0.0776928604543209, 'real_loss': 0.07076837, 'fake_loss': 0.032836758}\n",
            "{'k': 0.05235281, 'measure': 0.0770935388430953, 'real_loss': 0.06840752, 'fake_loss': 0.03799325}\n",
            "{'k': 0.052433662, 'measure': 0.07679464708827435, 'real_loss': 0.070905626, 'fake_loss': 0.033106923}\n",
            "{'k': 0.052498307, 'measure': 0.07706056721694768, 'real_loss': 0.0658756, 'fake_loss': 0.037991673}\n",
            "{'k': 0.05125163, 'measure': 0.07732412744127214, 'real_loss': 0.06865573, 'fake_loss': 0.03945133}\n",
            "{'k': 0.051059786, 'measure': 0.07679790758527816, 'real_loss': 0.073158294, 'fake_loss': 0.035918772}\n",
            "{'k': 0.05115113, 'measure': 0.07645125858485699, 'real_loss': 0.06988668, 'fake_loss': 0.031885803}\n",
            "{'k': 0.05122647, 'measure': 0.07636770823970437, 'real_loss': 0.06907861, 'fake_loss': 0.04708331}\n",
            "{'k': 0.05086719, 'measure': 0.07629952519759536, 'real_loss': 0.081910655, 'fake_loss': 0.032409824}\n",
            "{'k': 0.050538775, 'measure': 0.07662184816226363, 'real_loss': 0.06808336, 'fake_loss': 0.036173355}\n",
            "{'k': 0.050024733, 'measure': 0.07671700070612132, 'real_loss': 0.06534687, 'fake_loss': 0.038002387}\n",
            "{'k': 0.04992645, 'measure': 0.07593972121924161, 'real_loss': 0.06829562, 'fake_loss': 0.032700077}\n",
            "{'k': 0.049698927, 'measure': 0.07567781323753298, 'real_loss': 0.07028961, 'fake_loss': 0.03491755}\n",
            "{'k': 0.049317632, 'measure': 0.0755668967384845, 'real_loss': 0.07881874, 'fake_loss': 0.03612698}\n",
            "{'k': 0.04946381, 'measure': 0.07539896212331951, 'real_loss': 0.077509195, 'fake_loss': 0.03586803}\n",
            "{'k': 0.048986986, 'measure': 0.07550280370935798, 'real_loss': 0.06430637, 'fake_loss': 0.030126601}\n",
            "{'k': 0.048446022, 'measure': 0.07553258309327066, 'real_loss': 0.074010685, 'fake_loss': 0.03353199}\n",
            "{'k': 0.047794435, 'measure': 0.07536840925179422, 'real_loss': 0.07342838, 'fake_loss': 0.037815873}\n",
            "{'k': 0.047708903, 'measure': 0.07478410151973366, 'real_loss': 0.069637075, 'fake_loss': 0.03483011}\n",
            "{'k': 0.04698462, 'measure': 0.07512524683587253, 'real_loss': 0.06431043, 'fake_loss': 0.03345886}\n",
            "{'k': 0.047019623, 'measure': 0.07471700523979961, 'real_loss': 0.07361659, 'fake_loss': 0.034884527}\n",
            "{'k': 0.046914592, 'measure': 0.07478986995853484, 'real_loss': 0.06819315, 'fake_loss': 0.035104297}\n",
            "{'k': 0.04649457, 'measure': 0.07476636706665159, 'real_loss': 0.06713836, 'fake_loss': 0.037236687}\n",
            "{'k': 0.046084646, 'measure': 0.07431769406981767, 'real_loss': 0.07043442, 'fake_loss': 0.033400092}\n",
            "{'k': 0.045658797, 'measure': 0.07437269672378898, 'real_loss': 0.07078991, 'fake_loss': 0.039848678}\n",
            "{'k': 0.045407847, 'measure': 0.07427306221053004, 'real_loss': 0.07285031, 'fake_loss': 0.038888868}\n",
            "{'k': 0.044483535, 'measure': 0.07433086429722607, 'real_loss': 0.06718771, 'fake_loss': 0.036285482}\n",
            "{'k': 0.04412758, 'measure': 0.07394639325514436, 'real_loss': 0.068450056, 'fake_loss': 0.036076963}\n",
            "{'k': 0.04399372, 'measure': 0.07398752078786493, 'real_loss': 0.06461939, 'fake_loss': 0.035308927}\n",
            "{'k': 0.043660402, 'measure': 0.07390872555039824, 'real_loss': 0.06460619, 'fake_loss': 0.033516508}\n",
            "{'k': 0.04333881, 'measure': 0.07365076869353653, 'real_loss': 0.06899379, 'fake_loss': 0.038731217}\n",
            "{'k': 0.043387625, 'measure': 0.07332299613952636, 'real_loss': 0.06521478, 'fake_loss': 0.03734092}\n",
            "{'k': 0.043182388, 'measure': 0.07349618006870151, 'real_loss': 0.062699325, 'fake_loss': 0.034805674}\n",
            "{'k': 0.04294103, 'measure': 0.07312337947264314, 'real_loss': 0.07158196, 'fake_loss': 0.033554584}\n",
            "{'k': 0.042719144, 'measure': 0.07319403918087483, 'real_loss': 0.065716214, 'fake_loss': 0.036901094}\n",
            "{'k': 0.04252661, 'measure': 0.07267142555862666, 'real_loss': 0.07248064, 'fake_loss': 0.03381223}\n",
            "{'k': 0.042117327, 'measure': 0.0729317941647023, 'real_loss': 0.06841727, 'fake_loss': 0.037419166}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}